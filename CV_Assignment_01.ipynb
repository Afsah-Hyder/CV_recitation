{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afsah-Hyder/CV_recitation/blob/main/CV_Assignment_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBLGufOFk_mC",
        "outputId": "974f249f-d02f-4577-eb87-e7b9993f5b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#For Q3.\n",
        "# Specify the proportion of data for the validation set (e.g., 20%)\n",
        "test_size = 0.2\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    x_train, y_train, test_size=test_size, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHvkDYfS2tiJ"
      },
      "source": [
        "**CIFAR-10 Dataset:** The dataset contains 60,000 32x32 color (rgb) images categorized into 10 classes. It is a well-known benchmark dataset utilized for training and assessing machine learning algorithms, especially those designed for image recognition. Out of these 60,000 images, 50k are reserved for training and the remaining 10k for test. The 10 classes are: airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Each class contains 6k images.\n",
        "\n",
        "\n",
        "**Preprocessing steps:** In the preprocessing phase of image data, various steps are undertaken to optimize the image for analysis. These steps encompass noise reduction, contrast enhancement, image resizing, color correction, segmentation, feature extraction, among others. Noise reduction methodologies focus on eliminating unwanted elements, such as variations in lighting, while preserving the image's crucial characteristics. Contrast enhancement procedures are employed to heighten the distinction between different features within the image. Image resizing and color correction techniques play roles in adjusting the image's dimensions and color balance, respectively. Segmentation approaches divide the image into distinct regions based on its content, and feature extraction methods identify and extract important features. This preprocessing is vital in image analysis, contributing to improved data quality and reduced visual clutter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKPbiX7h-RpQ"
      },
      "source": [
        "**Q2.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLLmcr-o4Ezu",
        "outputId": "b38c806d-0afb-462b-a2ca-2ae41371ef2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72.0 , \n",
            "189.0 , \n",
            "237.0 , \n",
            "243.0 , \n",
            "126.0 , \n",
            "\n",
            "\n",
            "123.0 , \n",
            "276.0 , \n",
            "378.0 , \n",
            "417.0 , \n",
            "264.0 , \n",
            "\n",
            "\n",
            "117.0 , \n",
            "255.0 , \n",
            "378.0 , \n",
            "432.0 , \n",
            "294.0 , \n",
            "\n",
            "\n",
            "81.0 , \n",
            "156.0 , \n",
            "234.0 , \n",
            "309.0 , \n",
            "234.0 , \n",
            "\n",
            "\n",
            "30.0 , \n",
            "69.0 , \n",
            "93.0 , \n",
            "135.0 , \n",
            "96.0 , \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def calc(input,filter,padds,padding):\n",
        "  if padding:\n",
        "    input=np.pad(input,(padds, padds), constant_values=0)  # diff options available if different type of padding required along diff axis\n",
        "  output=np.zeros((len(input)-2*padds,len(input)-2*padds))\n",
        "  for i in range(padds,len(input)-padds):\n",
        "    for j in range(padds,len(input[i])-padds):\n",
        "      sum=input[i][j]*filter[padds][padds]\n",
        "      for k in range(1,padds+1):\n",
        "        sum+= input[i-k][j-k]*filter[padds-k][padds-k]+ input[i-k][j]*filter[padds-k][padds]+ input[i][j-k]*filter[padds][padds-k]+ input[i+k][j-k]*filter[padds+k][padds-k]+ input[i+k][j]*filter[padds+k][padds]+ input[i][j+k]*filter[padds][padds+k]+ input[i-k][j+k]*filter[padds-k][padds+k]+ input[i+k][j+k]*filter[padds+k][padds+k]\n",
        "      output[i-padds][j-padds]=sum\n",
        "  return output\n",
        "\n",
        "\n",
        "def filt(input,filter,padding,normalization):\n",
        "  if normalization: filter=filter/np.sum(filter)\n",
        "  filter_num=len(filter)\n",
        "  padds=int((filter_num-1)/2)    #pad width\n",
        "\n",
        "  if input.ndim==3:\n",
        "    output_0=calc(input[0],filter,padds,padding)\n",
        "    output_1=calc(input[1],filter,padds,padding)\n",
        "    output_2=calc(input[2],filter,padds,padding)\n",
        "\n",
        "    for i in range(0,len(output_0)):\n",
        "      for j in range(0,len(output_0)):\n",
        "        output_0[i][j]=output_0[i][j]+output_1[i][j]+output_2[i][j]\n",
        "    return output_0\n",
        "  elif input.ndim==2:\n",
        "    output=calc(input,filter,padds,padding)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def printer(output):\n",
        "  for i in range(len(output)):\n",
        "    for j in range(len(output[i])):\n",
        "      print(output[i][j], \", \")\n",
        "    print(\"\\n\")\n",
        "\n",
        "filter=np.ones((3,3))\n",
        "image3=np.array([[[3,4,12,2,5],[3,14,27,20,15],[3,14,12,21,25],[2,3,7,8,9],[2,3,6,4,11]],[[3,4,12,2,5],[3,14,27,20,15],[3,14,12,21,25],[2,3,7,8,9],[2,3,6,4,11]],[[3,4,12,2,5],[3,14,27,20,15],[3,14,12,21,25],[2,3,7,8,9],[2,3,6,4,11]]]) #3D\n",
        "image2=np.array([[3,4,12,2,5],[3,14,27,20,15],[3,14,12,21,25],[2,3,7,8,9],[2,3,6,4,11]])   #2D\n",
        "\n",
        "output=filt(image3,filter,1,0)\n",
        "printer(output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9faX_Iz-Vot"
      },
      "source": [
        "**Q3.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import local_binary_pattern, hog\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from os import listdir\n",
        "from google.colab.patches import cv2_imshow\n",
        "from os.path import isfile, join\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "pNlaj638zCGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "40wuKLLE-Qb9"
      },
      "outputs": [],
      "source": [
        "def get_hog_data(x_images, y_gt , width, height, orient = 9, pixelsxcell = (12, 12), cellsxblock = (3, 3)):\n",
        "\n",
        "    # Define the feature vector size\n",
        "    # Feature size = ((image rows / cell size (rows)) - (Cells per block (rows) -1))*\n",
        "    #                 (image cols / cell size (cols)) - (Cells per block (cols) -1))*\n",
        "    #                 (Cells per block (rows) * Cells per block (cols) * Orientations)\n",
        "    feature_size = int(np.trunc((height/pixelsxcell[0])-(cellsxblock[0]-1))*np.trunc((width/pixelsxcell[1])-(cellsxblock[1]-1))\\\n",
        "                    *(cellsxblock[0]*cellsxblock[1]*orient))\n",
        "\n",
        "    # Define arrays to save all HOG features and GT\n",
        "    X = np.empty([0,feature_size])\n",
        "    c\n",
        "    # For each class\n",
        "    for n in range(len(x_images)):\n",
        "        Xp = np.zeros((1,feature_size))\n",
        "        Yp = np.zeros((1, 1))\n",
        "\n",
        "        # Read image\n",
        "        img = x_images[n]\n",
        "        img=np.mean(img, axis=2)\n",
        "        print(np.shape(img))\n",
        "        cv2_imshow(img)\n",
        "        # Get HOG features for image (Xp) and GT (Yp)\n",
        "        Xp, hog_image = hog(img, orientations=orient, pixels_per_cell=pixelsxcell, cells_per_block=cellsxblock, visualize=True)\n",
        "\n",
        "        Yp = y_gt[n].reshape((1, 1))\n",
        "        print(Yp)\n",
        "        # Plot HOG image\n",
        "        #plot_hog_image(img, hog_image)\n",
        "        # Save features and GT in X and Y arrays\n",
        "        X = np.append(X, Xp, axis = 0) #axis=0 means the arrays are concatenated along the rows\n",
        "        Y = np.append(Y, Yp[0], axis = 0)\n",
        "        print(np.shape(hog_image))\n",
        "    #X = preprocessing.normalize(X)\n",
        "    # Return features and GT\n",
        "    return X, Y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the HOG image resulting from scikit-learnhog() function\n",
        "def c(img, hog_image):\n",
        "    # Define two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
        "    # Plot original image\n",
        "    ax1.axis('off')\n",
        "    ax1.imshow(img, cmap=plt.cm.gray)\n",
        "    ax1.set_title('Input image')\n",
        "    # Plot HOG image\n",
        "    ax2.axis('off')\n",
        "    ax2.imshow(hog_image, cmap=plt.cm.gray)\n",
        "    ax2.set_title('Histogram of Oriented Gradients')"
      ],
      "metadata": {
        "id": "4giWmigny_wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "ZkvsOTsemDVE",
        "outputId": "0c6c0c1c-0c9a-46c9-ab36-94fed02b2e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extract Histogram of Gradients features for training, validation and testing datasets:\n",
            "\n",
            "(32, 32)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADTElEQVR4nC3KzU8bRxgH4N87M7v22ruusTHGQMJHykdpqFCiHFq1USv1VvUf7L+RSy7tIWqlqBEEIoVQEkMxAfyBAdtr7856Zt5e+pwfWldB3bUcIGQjP/ZLsF6WFnJWSC0QT7Ry06kOmJwB92uaRnkYm/gFQ9nU5I0Vih1lihEGFMy2xqWcBgl/4m/2rqXy81opAijLrTyvd6PGi+sH43uTqpz3rHowLEptpadAnNZ/+mq3djSIfqbSyR9Zbmd3Pnwxm5sgtqSU42j78fNCNet0JsMT7adb3z2dff3x0VbrjdU8NQqlX36tV927V2fhnT3PuPL98qffr2t/3jkdIUukkquP60Grvd9t+GelpbtK9NderGZNI+zdZjkjpsqOhi97FJcCESyP5rdC6um5bJzgQTW74Cmccme/Rc/SLGpVFvXVFFkCc31bjP4txyRjZ60iwz9E/eBGX/iIUzm0Db4rhhfNb+rXCYyDYhetXiUeleK+Ksi0MZ2p1LOrXrTeaU58x6wQFRF9Ng/LspCyzBUnGGX9YGXm+rDrORBo88mWSfNesadCdr6daKkHdRKD4/PUl9axqi/eDbxubVINo0tvVEVnwXiF6eiwPZEAGCLTwoaemMnO0kKc3ptU4+uaa7ZTKeAcOxXfL/GdV/I63s1mLc+YRaqUPU0kkSMAYtwPC6PAxEEY9L6sBGFYIMXv7yWxdY4BZSd9v+Tflmv3+nPkPixESd1/1fSEA4EZELg8KS56cdoVufzejdA6mAzcVApBRABBkRkGlcuo4x7QfbO5al+XZlYDYYjBxAAUcdyOOVeLx31FB2ccY7G2tHhKBHYCDMV88+bh8lx/JfDG/5ghpBhkc9txWzHDKcuKga5cyNcHSfXdhZ+zhpOj8qpOYgLBChIA0N7/WN4QR8mTCA7kjlvR9rcRFBE7oQhMdDn49GPjpuHn9qdCYHhcW593f4+kIXa0AiYi5vJucKAf6feCGHLj6Yzovv3gAKI1MMCSLNbMabjzlgFYntkIg6W9PYAUgwAwE5/lPdu2AAQwuBGH1Z3eOTGtMQEAGGACSBhigPwgmX5Ru9BC8f8BAAEgIgAgPRauG8MZRQIEYgBggnROAGBUFjqFiWFX/A82SctYKceTkgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=32x32>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6]]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-dccf7545df6c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extract Histogram of Gradients features for training, validation and testing datasets:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mXtrain_d0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain_d0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hog_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mXval_d0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYval_d0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hog_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mXtest_d0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_d0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hog_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-7a75d387468a>\u001b[0m in \u001b[0;36mget_hog_data\u001b[0;34m(x_images, y_gt, width, height, orient, pixelsxcell, cellsxblock)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#plot_hog_image(img, hog_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Save features and GT in X and Y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#axis=0 means the arrays are concatenated along the rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhog_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5615\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5616\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5617\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
          ]
        }
      ],
      "source": [
        "width=32\n",
        "height=32\n",
        "\n",
        "print(\"Extract Histogram of Gradients features for training, validation and testing datasets:\\n\")\n",
        "Xtrain_d0, Ytrain_d0 = get_hog_data(X_train,Y_train, width, height)\n",
        "Xval_d0, Yval_d0 = get_hog_data(X_val,Y_val, width, height)\n",
        "Xtest_d0, Ytest_d0 = get_hog_data(x_test,y_test, width, height)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4**"
      ],
      "metadata": {
        "id": "PBMSR8qezDo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "((trainX, trainY), (testX, testY)) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydBpZOGIzFsu",
        "outputId": "1cf3d964-bd8d-4258-f8c1-7b4a71e8a805"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first \"flatten\" the image to be simple list of 28x28=784 pixels\n",
        "trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))\n",
        "testX = testX.reshape((testX.shape[0], 28 * 28 * 1))\n",
        "#we now have a 2D array with each index pixel intensities of the image as 1D array\n",
        "\n",
        "# scale data to the range of [0, 1]\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "\n",
        "print(trainX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SckMn5_yzj05",
        "outputId": "21c7e667-73c1-4b93-e75e-7b02507bc486"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMHW3M7w1AxT",
        "outputId": "e4f1a19e-8fc9-4a52-9149-1e9b83249dab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 0 4 ... 5 6 8]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPpiWPVrsTyypJlxXYz8B3g",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}